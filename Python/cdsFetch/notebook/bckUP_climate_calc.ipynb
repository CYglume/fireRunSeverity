{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea576f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import cdsapi\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "from datetime import datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from timezonefinder import TimezoneFinder\n",
    "import pytz\n",
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325588b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get root path under project folder structure\n",
    "cwd = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "root_folder = cwd.split('\\\\')\n",
    "root_folder = root_folder[1:-3]\n",
    "if root_folder[-1] != 'fireRunSeverity':\n",
    "    print(\"!!-- Didn't get correct root folder! --!!\")\n",
    "    print(root_folder)\n",
    "    print(\"!!-- Modify rooting index at line: 18 and come back --!!\")\n",
    "root_folder = os.path.join(os.sep,*root_folder)\n",
    "run_DataDir = r\"data/fireruns\"\n",
    "ER5_Dir     = r\"data/ER5\"\n",
    "\n",
    "# Local Side data\n",
    "# List in put data for GEE fetch\n",
    "AreaList = os.listdir(os.path.join(root_folder,run_DataDir))\n",
    "AreaList[0]\n",
    "os.path.exists(os.path.join(root_folder, ER5_Dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a7431",
   "metadata": {},
   "source": [
    "## Load Local side data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e109381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ######################################################\n",
      "Process AOI: GIF14_Au\n",
      "Shp Name: GIF14_32755_multipart.shp\n",
      "Shp  CRS: EPSG:32755\n",
      "{'type': 'Polygon', 'coordinates': (((148.797548490504, -37.78877807241547), (148.797548490504, -37.04608874283253), (150.0295287036503, -37.04608874283253), (150.0295287036503, -37.78877807241547), (148.797548490504, -37.78877807241547)),)}\n"
     ]
    }
   ],
   "source": [
    "in_Name = AreaList[0]\n",
    "print(\"\\n\\n ######################################################\")\n",
    "print(\"Process AOI:\", in_Name)\n",
    "dataFLD = os.path.join(root_folder, run_DataDir, in_Name)\n",
    "inFLD = os.path.join(dataFLD, 'input')\n",
    "shpIn  = []\n",
    "for f in os.scandir(inFLD):\n",
    "    if re.search(r\".shp$\", f.name):\n",
    "        print(\"Shp Name:\", f.name)\n",
    "        shpIn.append(f)\n",
    "\n",
    "if len(shpIn) != 1:\n",
    "    print(\"No. of shp file not equal to 1!\")\n",
    "    exit()\n",
    "else:\n",
    "    shpIn = shpIn[0]\n",
    "\n",
    "# Read Shp file\n",
    "shpGPD = gpd.read_file(os.path.join(inFLD, shpIn))\n",
    "print(\"Shp  CRS:\", shpGPD.crs)\n",
    "shp_reproj = shpGPD.to_crs(\"EPSG:4326\")\n",
    "# Get the bounds\n",
    "minx, miny, maxx, maxy = shp_reproj.total_bounds\n",
    "# Create a polygon of bounds\n",
    "bounds_polygon = Polygon([(minx, miny), (minx, maxy), (maxx, maxy), (maxx, miny), (minx, miny)])\n",
    "# Convert the polygon to GeoJSON\n",
    "json_polygon = mapping(bounds_polygon)\n",
    "print(json_polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf45a0",
   "metadata": {},
   "source": [
    "## Modify time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26bb1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate Time Zone: Australia/Melbourne\n"
     ]
    }
   ],
   "source": [
    "def get_timezone(lat, lon):\n",
    "    tf = TimezoneFinder()\n",
    "    tz_name = tf.timezone_at(lng=lon, lat=lat)\n",
    "    return tz_name\n",
    "\n",
    "latitude = (miny + maxy)/2\n",
    "longitude = (minx + maxx)/2\n",
    "timezone = get_timezone(latitude, longitude)\n",
    "print(f\"Accurate Time Zone: {timezone}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "843821c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process AOI: GIF14_Au\t\t\t2019 12\n",
      "Process AOI: isocronas_las_tablas\t\t\t2024 2\n",
      "Process AOI: LaJonquera\t\t\t2012 7\n",
      "Process AOI: LC1\t\t\t2020 8\n",
      "Process AOI: santa_ana_progresiones\t\t\t2023 2\n",
      "Process AOI: StLlorenc\t\t\t2003 8\n",
      "Process AOI: GIF11_Au\t\t\t2019 12\n",
      "Process AOI: GIF12_Au\t\t\t2019 12\n",
      "Process AOI: GIF15_Au\t\t\t2019 12\n",
      "Process AOI: LasMaquinas\t\t\t2017 1\n",
      "Process AOI: LC2\t\t\t2020 8\n",
      "Process AOI: PT_Alcobaca_15102017\t\t\t2017 10\n",
      "Process AOI: PT_Gois_17062017\t\t\t2017 6\n",
      "Process AOI: PT_Lousa_15102017\t\t\t2017 10\n",
      "Process AOI: PT_Monchique_03082018\t\t\t2018 8\n",
      "Process AOI: PT_PedrogaoGrande_17062017\t\t\t2017 6\n",
      "Process AOI: PT_Serta_23072017\t\t\t2017 7\n",
      "Process AOI: PT_FigueiradaFoz_15102017\t\t\t2017 10\n",
      "Process AOI: PT_OliveiraFrades_15102017\t\t\t2017 10\n",
      "Process AOI: PT_ParedesdeCoura_07082016\t\t\t2016 8\n",
      "Process AOI: PT_ProencaaNova_13092020\t\t\t2020 9\n",
      "Process AOI: PT_ViladeRei_20072019\t\t\t2019 7\n"
     ]
    }
   ],
   "source": [
    "for in_Name in AreaList:\n",
    "    print(\"Process AOI:\", in_Name, end=\"\\t\\t\\t\")\n",
    "    dataFLD = os.path.join(root_folder, run_DataDir, in_Name)\n",
    "    inFLD = os.path.join(dataFLD, 'input')\n",
    "    shpIn  = []\n",
    "    for f in os.scandir(inFLD):\n",
    "        if re.search(r\".shp$\", f.name):\n",
    "            # print(\"Shp Name:\", f.name)\n",
    "            shpIn.append(f)\n",
    "\n",
    "    if len(shpIn) != 1:\n",
    "        print(\"No. of shp file not equal to 1!\")\n",
    "        exit()\n",
    "    else:\n",
    "        shpIn = shpIn[0]\n",
    "\n",
    "    shpGPD = gpd.read_file(os.path.join(inFLD, shpIn))\n",
    "\n",
    "    # Get date of data\n",
    "    # Convert time zone to UTC\n",
    "    fire_dtString = list(shpGPD['FeHo'].dropna())\n",
    "    fire_dtsList  = [datetime.strptime(dt, \"%Y/%m/%d_%H%M\").replace(tzinfo=ZoneInfo(timezone)) for dt in fire_dtString if not re.search(\"\\\\D\", dt[:4])] # Filter out string with non-digit characters\n",
    "    tz_utc = pytz.timezone(\"UTC\")\n",
    "    fire_dtsList_UTC = [dt.astimezone(tz_utc) for dt in fire_dtsList]\n",
    "\n",
    "    # print(sorted(fire_dtsList_UTC))\n",
    "    dateSt = min(fire_dtsList_UTC).date()\n",
    "    print(dateSt.year, dateSt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7dad523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire start date and end date:\n",
      "2019-12-29 2020-02-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[datetime.date(1989, 12, 29), datetime.date(2019, 12, 29)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get date of data\n",
    "# Convert time zone to UTC\n",
    "fire_dtString = list(shpGPD['FeHo'].dropna())\n",
    "fire_dtsList  = [datetime.strptime(dt, \"%Y/%m/%d_%H%M\").replace(tzinfo=ZoneInfo(timezone)) for dt in fire_dtString if not re.search(\"\\\\D\", dt[:4])] # Filter out string with non-digit characters\n",
    "tz_utc = pytz.timezone(\"UTC\")\n",
    "fire_dtsList_UTC = [dt.astimezone(tz_utc) for dt in fire_dtsList]\n",
    "\n",
    "# print(sorted(fire_dtsList_UTC))\n",
    "dateSt = min(fire_dtsList_UTC).date()\n",
    "dateEd = max(fire_dtsList_UTC).date()\n",
    "print(\"Fire start date and end date:\")\n",
    "print(dateSt, dateEd)\n",
    "\n",
    "# Compute the date period for retrieving Satellite img\n",
    "prefire_Month  = [dateSt - relativedelta(months = 30*12), dateSt]\n",
    "prefire_Month\n",
    "# prefire_date = [d.strftime(\"%Y-%m-%d\") for d in prefire_date]\n",
    "\n",
    "# print(\"Pre- and Post- fire periods selected for satellite images:\")\n",
    "# print(prefire_date, postfire_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "032578dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2019, 7, 1), datetime.date(2019, 7, 30))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date(dateSt.year, dateSt.month, 1), date(dateSt.year, dateSt.month, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weather = [\"total_precipitation\", \"potential_evaporation\"]\n",
    "dataset = \"reanalysis-era5-single-levels-monthly-means\"\n",
    "\n",
    "for var in var_weather:\n",
    "    request = {\n",
    "        \"product_type\": [\"monthly_averaged_reanalysis\"],\n",
    "        \"variable\": [var],\n",
    "        \"year\": [\"1990\", \"2024\"],\n",
    "        \"month\": [\n",
    "            \"01\", \"02\", \"03\",\n",
    "            \"04\", \"05\", \"06\",\n",
    "            \"07\", \"08\", \"09\",\n",
    "            \"10\", \"11\", \"12\"\n",
    "        ],\n",
    "        \"time\": [\"00:00\"],\n",
    "        \"data_format\": \"grib\",\n",
    "        \"download_format\": \"unarchived\",\n",
    "        \"area\": [90, -180, -39, 180]\n",
    "    }\n",
    "\n",
    "    client = cdsapi.Client()\n",
    "    client.retrieve(dataset, request).download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45140406",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_weather = [\"2m_temperature\",\"2m_dewpoint_temperature\",\"10m_u_component_of_wind\",\"10m_v_component_of_wind\"]\n",
    "\n",
    "for var in var_weather:\n",
    "    os.makedirs(os.path.join(processed_path, \"Weather\", \"CDS\", var),\n",
    "                exist_ok=True)\n",
    "\n",
    "if fetch:\n",
    "    c = cdsapi.Client(key=cdsAPI_KEY,\n",
    "                    url='https://cds.climate.copernicus.eu/api', quiet=False, sleep_max=5, timeout=7200)\n",
    "\n",
    "    firstRun = True\n",
    "    for var in var_weather:\n",
    "        print(f\"\\n...Downloading {var}...\")\n",
    "        if os.path.exists(os.path.join(processed_path,\"Weather\", f\"era5_{var}.nc\")):\n",
    "            print(\"Exists: \", os.path.join(processed_path,\"Weather\", f\"era5_{var}.nc\"))\n",
    "            continue\n",
    "\n",
    "        downloaded_files = []\n",
    "        print(f\"Requesting......\")\n",
    "        for (year, month), dayRange in dates_by_month.items():\n",
    "            print(f\"{year}-{month}\", end=\" \")\n",
    "            output_file = os.path.join(processed_path, \"Weather\", \"CDS\", var,\n",
    "                                        f\"era5_land_{year}_{month}_{dayRange[0]}-{dayRange[1]-1}_12UTC.nc\")\n",
    "            if os.path.exists(output_file):\n",
    "                continue\n",
    "\n",
    "            c.retrieve(\n",
    "                'reanalysis-era5-land',\n",
    "                {\n",
    "                    \"variable\": [var],\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'day': [f\"{i:02}\" for i in range(*dayRange)],\n",
    "                    'time': time_of_day,\n",
    "                    \"area\": area_extract_cds,\n",
    "                    \"data_format\": \"netcdf\",\n",
    "                    \"download_format\": \"unarchived\",\n",
    "                },\n",
    "                output_file\n",
    "            )\n",
    "\n",
    "            if firstRun:\n",
    "                c = cdsapi.Client(key=cdsAPI_KEY, \n",
    "                        url='https://cds.climate.copernicus.eu/api', quiet=True, sleep_max=5, timeout=7200, progress=False)\n",
    "                firstRun = False\n",
    "\n",
    "            downloaded_files.append(output_file)\n",
    "\n",
    "        print(\"\\nMerging NetCDF files...\")\n",
    "        merged_file = os.path.join(processed_path, \"Weather\", f\"era5_{var}.nc\")\n",
    "        if os.path.exists(merged_file):\n",
    "            print(f\"File already exists: {merged_file}\")\n",
    "            continue\n",
    "\n",
    "        datasets = [xr.open_dataset(f, engine='netcdf4') for f in downloaded_files]\n",
    "        merged = xr.concat(datasets, dim='valid_time')\n",
    "        merged.to_netcdf(merged_file)\n",
    "        print(f\"Saved merged NetCDF as {merged_file}\\n\")\n",
    "\n",
    "    print(\"Extraction from CDS API finished\")\n",
    "    return True\n",
    "else:\n",
    "    print(\"Weather data not fetched\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2738e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"satellite-land-cover\"\n",
    "request = {\n",
    "  \"variable\": \"all\",\n",
    "  \"year\": [\n",
    "    \"2014\", \"2017\", \"2019\",\n",
    "    \"2022\"\n",
    "  ],\n",
    "  \"version\": [\n",
    "    \"v2_0_7cds\",\n",
    "    \"v2_1_1\"\n",
    "  ],\n",
    "  \"area\": [90, -180, -90, 180]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geefetch-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
