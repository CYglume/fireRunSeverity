{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap\n",
        "import os, re, json, time\n",
        "import geopandas as gpd\n",
        "from datetime import datetime, timedelta, date\n",
        "from shapely.geometry import Polygon, mapping\n",
        "from timezonefinder import TimezoneFinder\n",
        "import pytz\n",
        "from zoneinfo import ZoneInfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start Connection with Google Earth Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ee.Authenticate(force=True)\n",
        "ee.Initialize(project = \"project-ID\") # specify the project name in the argument.\n",
        "print(ee.String('Hello from the Earth Engine servers!').getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up environmental variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To get root path under project folder structure\n",
        "cwd = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "root_folder = cwd.split('\\\\')\n",
        "root_folder = root_folder[0:-3]\n",
        "if root_folder[-1] != 'fireRunSeverity':\n",
        "    print(\"!!-- Didn't get correct root folder! --!!\")\n",
        "    print(root_folder)\n",
        "    print(\"!!-- Modify rooting index at line: 18 and come back --!!\")\n",
        "if re.search(r\":\", root_folder[0]):\n",
        "    root_folder = os.path.join(root_folder[0], os.sep, *root_folder[1:])\n",
        "else:\n",
        "    root_folder = os.path.join(os.sep,*root_folder)\n",
        "\n",
        "# Local Side data\n",
        "# List in put data for GEE fetch\n",
        "if os.path.isfile('geeIDS.json'):\n",
        "    with open('geeIDS.json', 'r', encoding='utf-8') as f:\n",
        "        exist_indicesList_json = json.load(f)\n",
        "run_DataDir = r\"data/fireruns\"\n",
        "AreaList = os.listdir(os.path.join(root_folder,run_DataDir))\n",
        "in_Name = AreaList[5]\n",
        "in_Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if any index map has been calculated\n",
        "outGEEFLD = os.path.join(root_folder, 'data', 'GEE', in_Name)\n",
        "if not os.path.isdir(outGEEFLD):\n",
        "    os.makedirs(outGEEFLD)\n",
        "exist_indicesList = os.listdir(outGEEFLD)\n",
        "exist_indicesList = [f.split(\"--\")[0] for f in exist_indicesList if os.path.isfile(os.path.join(outGEEFLD, f))]\n",
        "if 'exist_indicesList_json' in locals():\n",
        "    if in_Name in exist_indicesList_json.keys():\n",
        "        for exist_id in exist_indicesList_json[in_Name]:\n",
        "            if exist_id not in exist_indicesList:\n",
        "                exist_indicesList.append(exist_id)\n",
        "exist_indicesList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load EE side data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Online Data Collection (Run for all process)\n",
        "# Add Earth Engine dataset\n",
        "S2_harmon = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
        "L7_T1L2   = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\")\n",
        "SRTM      = ee.Image(\"USGS/SRTMGL1_003\")\n",
        "SPEI      = ee.ImageCollection(\"CSIC/SPEI/2_10\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Local side data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\\n ######################################################\")\n",
        "print(\"Process AOI:\", in_Name)\n",
        "dataFLD = os.path.join(root_folder, run_DataDir, in_Name)\n",
        "inFLD = os.path.join(dataFLD, 'input')\n",
        "shpIn  = []\n",
        "for f in os.scandir(inFLD):\n",
        "    if re.search(r\".shp$\", f.name):\n",
        "        print(f.name)\n",
        "        shpIn.append(f)\n",
        "\n",
        "if len(shpIn) != 1:\n",
        "    print(\"No. of shp file not equal to 1!\")\n",
        "    exit()\n",
        "else:\n",
        "    shpIn = shpIn[0]\n",
        "\n",
        "# Read Shp file\n",
        "shpGPD = gpd.read_file(os.path.join(inFLD, shpIn))\n",
        "print(shpGPD.crs)\n",
        "shp_reproj = shpGPD.to_crs(\"EPSG:4326\")\n",
        "# Get the bounds\n",
        "minx, miny, maxx, maxy = shp_reproj.total_bounds\n",
        "# Create a polygon of bounds\n",
        "bounds_polygon = Polygon([(minx, miny), (minx, maxy), (maxx, maxy), (maxx, miny), (minx, miny)])\n",
        "# Convert the polygon to GeoJSON\n",
        "json_polygon = mapping(bounds_polygon)\n",
        "print(json_polygon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modify time zone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latitude = (miny + maxy)/2\n",
        "longitude = (minx + maxx)/2\n",
        "tf = TimezoneFinder()\n",
        "timezone = tf.timezone_at(lng=longitude, lat=latitude)\n",
        "print(f\"Accurate Time Zone: {timezone}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get date of data\n",
        "# Convert time zone to UTC\n",
        "fire_dtString = list(shpGPD['FeHo'].dropna())\n",
        "fire_dtsList  = [datetime.strptime(dt, \"%Y/%m/%d_%H%M\").replace(tzinfo=ZoneInfo(timezone)) for dt in fire_dtString if not re.search(\"\\\\D\", dt[:4])] # Filter out string with non-digit characters\n",
        "tz_utc = pytz.timezone(\"UTC\")\n",
        "fire_dtsList_UTC = [dt.astimezone(tz_utc) for dt in fire_dtsList]\n",
        "\n",
        "# print(sorted(fire_dtsList_UTC))\n",
        "dateSt = min(fire_dtsList_UTC).date()\n",
        "dateEd = max(fire_dtsList_UTC).date()\n",
        "print(\"Fire start date and end date:\")\n",
        "print(dateSt, dateEd)\n",
        "\n",
        "L7_flag = False # for using Landsat-7 dataset if burning timing before Sentinel-2\n",
        "if dateSt < date(2017, 3, 28):\n",
        "    print(\"!! ---------- Date before 28 Mar 2017! ---------- !!\")\n",
        "    print(\"----- AOI: \", in_Name, \" -----\")\n",
        "    print(\"----- Using Landsat 7 ......\")\n",
        "    L7_flag = True\n",
        "\n",
        "SPEI_flag = True\n",
        "if dateSt > date(2023, 12, 31):\n",
        "    print(\"----- Date after 2023/12 is not available -----\")\n",
        "    print(\"----- AOI: \", in_Name, \" -----\")\n",
        "    SPEI_flag = False\n",
        "\n",
        "# Compute the date period for retrieving Satellite img\n",
        "prefire_date  = [dateSt - timedelta(days = 4*30), dateSt - timedelta(days = 1)]\n",
        "postfire_date = [dateEd + timedelta(days = 1),    dateEd + timedelta(days = 4*30)]\n",
        "\n",
        "prefire_date = [d.strftime(\"%Y-%m-%d\") for d in prefire_date]\n",
        "postfire_date = [d.strftime(\"%Y-%m-%d\") for d in postfire_date]\n",
        "\n",
        "print(\"Pre- and Post- fire periods selected for satellite images:\")\n",
        "print(prefire_date, postfire_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload data to EE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clipAOI = ee.Geometry.Polygon(json_polygon[\"coordinates\"])\n",
        "clipAOI2 = clipAOI.buffer(50000)\n",
        "print(clipAOI.getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (GEE) Process satellite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Functions for Computing Necessary indices\n",
        "def func_maskClouds(image):\n",
        "    imgCLP = image.select(\"MSK_CLDPRB\")\n",
        "    mskCLP = imgCLP.lt(10)  \n",
        "    qa = image.select(\"QA60\")\n",
        "    Clouds = qa.bitwiseAnd(1 << 10).eq(0)  \n",
        "    Cirrus = qa.bitwiseAnd(1 << 11).eq(0) \n",
        "    mask = Clouds.And(Cirrus).And(mskCLP)\n",
        "    return image.updateMask(mask)\n",
        "\n",
        "def maskClouds_L7(image):\n",
        "    qa = image.select('QA_PIXEL')\n",
        "    dilated_cloud = qa.bitwiseAnd(1 << 1).eq(0)\n",
        "    cloud = qa.bitwiseAnd(1 << 3).eq(0)\n",
        "    cloud_sha = qa.bitwiseAnd(1 << 4).eq(0)\n",
        "    mask = cloud.And(cloud_sha).And(dilated_cloud)\n",
        "    return image.updateMask(mask)\n",
        "\n",
        "def func_rescale(image, scale, offset):\n",
        "    refl = image.multiply(scale).add(offset)\n",
        "    return refl.copyProperties(image, [\"system:time_start\", 'system:index'])\n",
        "\n",
        "def func_calcIndices(image, RED, NIR, SWIR):\n",
        "    NBR = image.normalizedDifference([NIR, SWIR]).rename(\"NBR\") \n",
        "    NDVI = image.normalizedDifference([NIR, RED]).rename(\"NDVI\") \n",
        "    return image.addBands([NBR, NDVI])\n",
        "\n",
        "def func_calcIndices2(image):\n",
        "    Cl_RBR   = image.expression(\n",
        "        \"dNBR / (preNBR + 1.001)\", {\n",
        "            \"preNBR\": image.select('Cl_preNBR'),\n",
        "            \"dNBR\": image.select('Cl_dNBR') \n",
        "        }\n",
        "    ).rename('Cl_RBR').toFloat()\n",
        "    Cl_RdNBR = image.expression(\n",
        "        \"(abs(preNBR) < 0.001) ? dNBR/sqrt(0.001) : dNBR/sqrt(abs(preNBR))\",{\n",
        "            \"preNBR\": image.select('Cl_preNBR'),\n",
        "            \"dNBR\": image.select('Cl_dNBR')\n",
        "        }\n",
        "    ).rename(\"Cl_RdNBR\").toFloat()\n",
        "    M_RBR   = image.expression(\n",
        "        \"dNBR / (preNBR + 1.001)\", {\n",
        "            \"preNBR\": image.select('M_preNBR'),\n",
        "            \"dNBR\": image.select('M_dNBR') \n",
        "        }\n",
        "    ).rename('M_RBR').toFloat()\n",
        "    M_RdNBR = image.expression(\n",
        "        \"(abs(preNBR) < 0.001) ? dNBR/sqrt(0.001) : dNBR/sqrt(abs(preNBR))\",{\n",
        "            \"preNBR\": image.select('M_preNBR'),\n",
        "            \"dNBR\": image.select('M_dNBR')\n",
        "        }\n",
        "    ).rename(\"M_RdNBR\").toFloat()\n",
        "    return image.addBands([Cl_RBR, Cl_RdNBR, M_RBR, M_RdNBR])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter data region and date\n",
        "bandList = [\"SR_B.\", \"SR_CLOUD_QA\", \"QA_PIXEL\"] if L7_flag else [\"B.\", \"B..\", \"QA60\", \"MSK_CLDPRB\"]\n",
        "band_SPEI = [\"SPEI_03_month\", \"SPEI_06_month\", \"SPEI_09_month\", \"SPEI_12_month\"]\n",
        "\n",
        "if not L7_flag:\n",
        "    S2_pre_select = S2_harmon.filterDate(prefire_date[0], prefire_date[1]) \\\n",
        "        .filterBounds(clipAOI2).select(bandList)\n",
        "    S2_pos_select = S2_harmon.filterDate(postfire_date[0], postfire_date[1]) \\\n",
        "        .filterBounds(clipAOI2).select(bandList)\n",
        "else:\n",
        "    L7_pre_select = L7_T1L2.filterDate(prefire_date[0], prefire_date[1]) \\\n",
        "        .filterBounds(clipAOI2).select(bandList)\n",
        "    L7_pos_select = L7_T1L2.filterDate(postfire_date[0], postfire_date[1]) \\\n",
        "        .filterBounds(clipAOI2).select(bandList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time compositing imageCollections\n",
        "if not L7_flag:\n",
        "    # Mosaicking composite\n",
        "    S2pre = S2_pre_select.map(func_maskClouds) \\\n",
        "        .map(lambda image: func_rescale(image, scale=0.0001, offset=0)) \\\n",
        "        .sort('system:time_start') \\\n",
        "        .mosaic(); \n",
        "    S2pos = S2_pos_select.map(func_maskClouds) \\\n",
        "        .map(lambda image: func_rescale(image, scale=0.0001, offset=0)) \\\n",
        "        .sort('system:time_start', False) \\\n",
        "        .mosaic(); \n",
        "    # print(json.dumps(S2pre.getInfo(), indent=4))\n",
        "\n",
        "    # Mean composite\n",
        "    S2pre_mean = S2_pre_select.map(func_maskClouds) \\\n",
        "        .map(lambda image: func_rescale(image, scale=0.0001, offset=0)) \\\n",
        "        .mean(); \n",
        "    S2pos_mean = S2_pos_select.map(func_maskClouds) \\\n",
        "        .map(lambda image: func_rescale(image, scale=0.0001, offset=0)) \\\n",
        "        .mean(); \n",
        "    # print(json.dumps(S2pre_mean.getInfo(), indent=4))\n",
        "else:  \n",
        "    # Mosaicking composite\n",
        "    L7pre = L7_pre_select.map(maskClouds_L7) \\\n",
        "        .map(lambda image: func_rescale(image, 0.0000275, -0.2)) \\\n",
        "        .sort('system:time_start')  \\\n",
        "        .mosaic()\n",
        "    L7pos = L7_pos_select.map(maskClouds_L7) \\\n",
        "        .map(lambda image: func_rescale(image, 0.0000275, -0.2)) \\\n",
        "        .sort('system:time_start', False) \\\n",
        "        .mosaic()\n",
        "    # print(json.dumps(L7pre.getInfo(), indent=4))\n",
        "    \n",
        "    # Mean composite\n",
        "    L7pre_mean = L7_pre_select.map(maskClouds_L7) \\\n",
        "        .map(lambda image: func_rescale(image, 0.0000275, -0.2)) \\\n",
        "        .mean()\n",
        "    L7pos_mean = L7_pos_select.map(maskClouds_L7) \\\n",
        "        .map(lambda image: func_rescale(image, 0.0000275, -0.2)) \\\n",
        "        .mean()\n",
        "    # print(json.dumps(L7pre_mean.getInfo(), indent=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not L7_flag:\n",
        "    # Indices Calculation\n",
        "    pre_id   = func_calcIndices(S2pre,      RED=\"B4\", NIR=\"B8\", SWIR=\"B12\")\n",
        "    pos_id   = func_calcIndices(S2pos,      RED=\"B4\", NIR=\"B8\", SWIR=\"B12\")\n",
        "    pre_id_m = func_calcIndices(S2pre_mean, RED=\"B4\", NIR=\"B8\", SWIR=\"B12\")\n",
        "    pos_id_m = func_calcIndices(S2pos_mean, RED=\"B4\", NIR=\"B8\", SWIR=\"B12\")\n",
        "else:  \n",
        "    # Indices Calculation\n",
        "    pre_id   = func_calcIndices(L7pre,      RED=\"SR_B3\", NIR=\"SR_B4\", SWIR=\"SR_B7\")\n",
        "    pos_id   = func_calcIndices(L7pos,      RED=\"SR_B3\", NIR=\"SR_B4\", SWIR=\"SR_B7\")\n",
        "    pre_id_m = func_calcIndices(L7pre_mean, RED=\"SR_B3\", NIR=\"SR_B4\", SWIR=\"SR_B7\")\n",
        "    pos_id_m = func_calcIndices(L7pos_mean, RED=\"SR_B3\", NIR=\"SR_B4\", SWIR=\"SR_B7\")\n",
        "\n",
        "\n",
        "# dNBR\n",
        "indices_first  = pre_id.select(\"NBR\").subtract(pos_id.select(\"NBR\")).multiply(1000).rename(\"Cl_dNBR\")\n",
        "indices_first  = indices_first.addBands(\n",
        "    pre_id_m.select(\"NBR\").subtract(pos_id_m.select(\"NBR\")).multiply(1000).rename(\"M_dNBR\")\n",
        ")\n",
        "\n",
        "# Other indices\n",
        "indices_first  = indices_first.addBands([pre_id.select(\"NBR\").rename(\"Cl_preNBR\"), \n",
        "                                            pos_id.select(\"NBR\").rename(\"Cl_posNBR\"),\n",
        "                                            pre_id_m.select(\"NBR\").rename(\"M_preNBR\"), \n",
        "                                            pos_id_m.select(\"NBR\").rename(\"M_posNBR\"),])\n",
        "\n",
        "indices_final = func_calcIndices2(indices_first)\n",
        "\n",
        "# Environmental factors\n",
        "terrain = ee.Terrain.products(SRTM.clip(clipAOI2));\n",
        "indices_final = indices_final.addBands([SRTM.clip(clipAOI2).select('elevation').rename('env_elevation'),\n",
        "                                        terrain.select('aspect').rename('env_aspect'),])\n",
        "\n",
        "# SPEI indices\n",
        "if SPEI_flag:\n",
        "    month_SPEI = (date(dateSt.year, dateSt.month, 1).strftime(\"%Y-%m-%d\"), date(dateSt.year, dateSt.month, 28).strftime(\"%Y-%m-%d\"))\n",
        "    spei_flt = SPEI.filterDate(month_SPEI[0], month_SPEI[1]) \\\n",
        "        .filterBounds(clipAOI2).first() # Select the only image\n",
        "    indices_final = indices_final.addBands(spei_flt.select(band_SPEI))\n",
        "\n",
        "indices_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output image to Google drive folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select needed bands\n",
        "bd = indices_final.bandNames()\n",
        "bd = bd.removeAll(['Cl_preNBR', 'Cl_posNBR', 'M_preNBR', 'M_posNBR'])\n",
        "indices_for_output = indices_final.select(bd)\n",
        "bd = indices_for_output.bandNames().getInfo()\n",
        "print(bd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define export parameters\n",
        "print(\"#-----------------#\")\n",
        "print(\"Exporting for\", in_Name)\n",
        "driveFLD = os.path.join('EarthEngineFolder', in_Name, in_Name)\n",
        "tStamp = datetime.now().strftime(\"%d%m%Y_%H%M\")\n",
        "datasetName = \"L7\" if L7_flag else \"S2\"\n",
        "for bd_i in bd:\n",
        "    if f'{datasetName}_{bd_i}' in exist_indicesList:\n",
        "        # skip map production if index maps already exist in local folder\n",
        "        continue\n",
        "\n",
        "    export_task = ee.batch.Export.image.toDrive(\n",
        "        image=indices_for_output.select(bd_i),\n",
        "        description='sentinel2_fire_indices_image_export',\n",
        "        folder='EarthEngineFolder',  # Folder in your Google Drive\n",
        "        fileNamePrefix=f'PythonGEE_output--{in_Name}--{datasetName}_{bd_i}--{tStamp}',  # File name prefix\n",
        "        region=clipAOI,  # Define the region to export (could be an area of interest)\n",
        "        scale=10,  # Spatial resolution in meters\n",
        "        fileFormat='GeoTIFF',  # File format\n",
        "        maxPixels=1e12  # Max pixels to export\n",
        "    )\n",
        "\n",
        "    # Start the export task\n",
        "    try:\n",
        "        export_task.start()\n",
        "        print(\"Band: \", bd_i)\n",
        "        print(\"Exporting to Google Drive...\")\n",
        "\n",
        "        # Check the status of the export task\n",
        "        print(\"Exporting... Please wait\")\n",
        "        while export_task.active():\n",
        "            print('.',  end=\"\")\n",
        "            time.sleep(10)\n",
        "\n",
        "        print('Export completed.')\n",
        "\n",
        "    except ee.ee_exception.EEException as e:\n",
        "        print(f\"Error during export: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Miscellaneous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Miscellaneous: Counting pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pixel_count = S2_dNBR.select('dNBR').reduceRegion(\n",
        "#     reducer=ee.Reducer.count(),\n",
        "#     geometry=clipAOI,  # Use the image's geometry as the region\n",
        "#     scale=10,  # Spatial resolution in meters\n",
        "#     maxPixels=1e10  # Maximum number of pixels to process\n",
        "# )\n",
        "\n",
        "# # Print the pixel count\n",
        "# print('Pixel count for B4 band:', pixel_count.getInfo())"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "geefetch-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
